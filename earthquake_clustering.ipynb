{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcG7Ie/uBD2ALbTENrSA1s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jakewalter/frontiers_geophysics/blob/main/earthquake_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRNPPcJDP2Kd"
      },
      "outputs": [],
      "source": [
        "!pip install basemap\n",
        "import pandas as pd\n",
        "import matplotlib.path as mpltPath\n",
        "from sklearn.cluster import DBSCAN\n",
        "from mpl_toolkits.basemap import Basemap\n",
        "import numpy as np\n",
        "\n",
        "catdf = pd.read_csv('http://wichita.ogs.ou.edu/eq/catalog/complete/complete.csv')\n",
        "\n",
        "#eqtempin = catdf[['latitude','longitude']].to_numpy()\n",
        "#eqpath = mpltPath.Path(polygon)\n",
        "#insidestate = eqpath.contains_points(eqtempin)\n",
        "#catdf = catdf[insidestate]\n",
        "\n",
        "#catdf = catdf.reset_index(drop=True)\n",
        "catdf['origintime'] = pd.to_datetime(catdf['origintime'])\n",
        "catdf['magnitude'] = catdf['magnitude'].str.replace(\"None\", \"0\").astype(float)\n",
        "catdf['magnitude'] = catdf['magnitude'].astype(float)\n",
        "#catdf = catdf[(catdf['origintime']>time1) & (catdf['origintime']<time2)]\n",
        "catdf.sort_values(by=['origintime'], inplace=True)\n",
        "lat_a = 36.36\n",
        "lat_b = 36.49\n",
        "lon_a = -97.01\n",
        "lon_b = -96.80\n",
        "\n",
        "catdf = catdf[(catdf['latitude']>lat_a) & (catdf['latitude']<lat_b) & (catdf['longitude']>lon_a) & (catdf['longitude']<lon_b)]\n",
        "\n",
        "catdf = catdf.reset_index(drop=True)\n",
        "\n",
        "#\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(catdf['longitude'], catdf['latitude'],'k.')\n",
        "\n"
      ],
      "metadata": {
        "id": "rHAWr_O9QU1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have an earthquake catalog, we seek to cluster the events spatially ..."
      ],
      "metadata": {
        "id": "8dKzKGUH5bpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "map = Basemap(llcrnrlon=-104,llcrnrlat=33,urcrnrlon=-93,urcrnrlat=38, resolution='l', projection='tmerc',lat_0=35,lon_0=-98)\n",
        "x,y = map(np.array((catdf['longitude'])),np.array((catdf['latitude'])))\n",
        "X=np.transpose(np.array((x,y)))\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.cluster import DBSCAN\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html\n",
        "from sklearn import metrics\n",
        "\n",
        "eps_value = 2000\n",
        "db = DBSCAN(eps=eps_value, min_samples=10).fit(X)\n",
        "labels = db.labels_\n",
        "\n",
        "# Number of clusters in labels, ignoring noise if present.\n",
        "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "n_noise_ = list(labels).count(-1)\n",
        "\n",
        "print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
        "print(\"Estimated number of noise points: %d\" % n_noise_)"
      ],
      "metadata": {
        "id": "lJqn0Fm85hSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_labels = set(labels)\n",
        "core_samples_mask = np.zeros_like(labels, dtype=bool)\n",
        "core_samples_mask[db.core_sample_indices_] = True\n",
        "\n",
        "colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
        "for k, col in zip(unique_labels, colors):\n",
        "    if k == -1:\n",
        "        # Black used for noise.\n",
        "        col = [0, 0, 0, 1]\n",
        "\n",
        "    class_member_mask = labels == k\n",
        "\n",
        "    xy = X[class_member_mask & core_samples_mask]\n",
        "    plt.plot(\n",
        "        xy[:, 0],\n",
        "        xy[:, 1],\n",
        "        \"o\",\n",
        "        markerfacecolor=tuple(col),\n",
        "        markeredgecolor=\"k\",\n",
        "        markersize=14,\n",
        "    )\n",
        "\n",
        "    xy = X[class_member_mask & ~core_samples_mask]\n",
        "    plt.plot(\n",
        "        xy[:, 0],\n",
        "        xy[:, 1],\n",
        "        \"o\",\n",
        "        markerfacecolor=tuple(col),\n",
        "        markeredgecolor=\"k\",\n",
        "        markersize=6,\n",
        "    )\n",
        "\n",
        "plt.title(f\"Estimated number of clusters: {n_clusters_}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SI-YunBJ_a3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you settle on the appropriate parameters for clustering, we can next attempt to find fault orientations. Note in the last section that we had a loop in order to plot the different clusters. This time, within the loop, let's fit a line."
      ],
      "metadata": {
        "id": "T8yGLDSDAe2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "\n",
        "for k in unique_labels:\n",
        "    #fig = plt.figure()\n",
        "    #ax = mplot3d.Axes3D(fig)\n",
        "    #print(k, col)\n",
        "    if k == -1:\n",
        "        # Black used for noise.\n",
        "        col = [0, 0, 0, 1]\n",
        "\n",
        "    class_member_mask = (labels == k)\n",
        "    #xy = X[class_member_mask & ~core_samples_mask]\n",
        "    #print(xy)\n",
        "\n",
        "\n",
        "    xy = X[class_member_mask & core_samples_mask]\n",
        "    if len(xy)>1:    #print(xy)\n",
        "      x1 = xy[:,0].reshape(-1,1)\n",
        "      y1 = xy[:,1]\n",
        "\n",
        "\n",
        "      # Fit line using all data\n",
        "      lr = linear_model.LinearRegression()\n",
        "      lr.fit(x1, y1)\n",
        "\n",
        "      # Robustly fit linear model with RANSAC algorithm\n",
        "      ransac = linear_model.RANSACRegressor()\n",
        "      ransac.fit(x1, y1)\n",
        "      # inlier_mask = ransac.inlier_mask_\n",
        "      # outlier_mask = np.logical_not(inlier_mask)\n",
        "\n",
        "      # Predict data of estimated models\n",
        "      line_X = np.arange(x1.min(), x1.max())[:, np.newaxis]\n",
        "      line_y = lr.predict(line_X)\n",
        "      line_y_ransac = ransac.predict(line_X)\n",
        "      plt.plot(xy[:,0],xy[:,1],'ro')\n",
        "      plt.plot(line_X, line_y_ransac, color='cornflowerblue', linewidth=2, label='RANSAC regression')\n",
        "      plt.plot(line_X, line_y, color='black', linewidth=2, label='Linear regression')\n",
        "      plt.legend()\n"
      ],
      "metadata": {
        "id": "0_PfQyIZAtFF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}